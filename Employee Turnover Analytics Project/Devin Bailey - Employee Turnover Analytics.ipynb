{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Devin Bailey\n",
    "January 29, 2024\n",
    "Emploee Turnover Analytics Project\n",
    "CB AIML Core: Machine Learning'''\n",
    "\n",
    "'''Develop a model to predict employee retention using Python.'''\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, precision_score, recall_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "import warnings\n",
    "\n",
    "# Ignore specific future warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel('1688640705_hr_comma_sep.xlsx')\n",
    "\n",
    "# 1. Data Quality Checks\n",
    "# Check for missing values, outliers, and inconsistent data types\n",
    "print(data.isnull().sum())\n",
    "print(data.describe())\n",
    "\n",
    "# 2. Exploratory Data Analysis (EDA)\n",
    "# Correlation Heatmap\n",
    "numeric_data = data.select_dtypes(include=[np.number])\n",
    "sns.heatmap(numeric_data.corr(), annot=True)\n",
    "plt.show()\n",
    "\n",
    "# Distribution Plots\n",
    "for col in ['satisfaction_level', 'last_evaluation', 'average_montly_hours']:\n",
    "    sns.histplot(data[col], kde=True)\n",
    "    plt.show()\n",
    "\n",
    "# Convert 'left' column to string type for plotting\n",
    "data['left'] = data['left'].astype(str)\n",
    "\n",
    "# Bar Plot of Employee Project Count\n",
    "sns.countplot(x='number_project', hue='left', data=data)\n",
    "plt.show()\n",
    "\n",
    "# 3. Clustering of Employees Who Left\n",
    "# Check if there are employees who left\n",
    "if (data['left'] == 1).any():\n",
    "    left_emp = data[data['left'] == 1][['satisfaction_level', 'last_evaluation']]\n",
    "\n",
    "    # Check if left_emp is not empty\n",
    "    if not left_emp.empty:\n",
    "        kmeans = KMeans(n_clusters=3).fit(left_emp)\n",
    "        left_emp['cluster'] = kmeans.labels_\n",
    "        sns.scatterplot(x='satisfaction_level', y='last_evaluation', hue='cluster', data=left_emp)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No valid data for employees who left.\")\n",
    "else:\n",
    "    print(\"No employees left in the dataset.\")\n",
    "\n",
    "\n",
    "# 4. Handle Class Imbalance with SMOTE\n",
    "X = pd.get_dummies(data.drop('left', axis=1))\n",
    "y = data['left'].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 5. Model Training with Cross-Validation\n",
    "kf = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\n",
    "log_reg_scores = cross_val_score(log_reg, X_train_sm, y_train_sm, cv=kf)\n",
    "print('LogisticRegression scores',log_reg_scores)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf_scores = cross_val_score(rf, X_train_sm, y_train_sm, cv=kf)\n",
    "print('RandomForestClassifier scores', rf_scores)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier()\n",
    "gb_scores = cross_val_score(gb, X_train_sm, y_train_sm, cv=kf)\n",
    "print('GradientBoostingClassifier scores', gb_scores)\n",
    "\n",
    "# Choose the best model based on cross-validation scores\n",
    "def evaluate_model(model, X, y, cv):\n",
    "    # Determine the model name\n",
    "    if isinstance(model, Pipeline):\n",
    "        model_name = model.steps[-1][0]  # Name of the last step in the pipeline\n",
    "    else:\n",
    "        model_name = model.__class__.__name__  # Class name of the model\n",
    "    \n",
    "    # Predict probabilities and classes\n",
    "    y_probas = cross_val_predict(model, X, y, cv=cv, method=\"predict_proba\")\n",
    "    y_preds = cross_val_predict(model, X, y, cv=cv)\n",
    "\n",
    "    # ROC/AUC\n",
    "    roc_auc = roc_auc_score(y, y_probas[:, 1])\n",
    "    print(f'{model_name} - ROC/AUC Score: {roc_auc}')\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_probas[:, 1])\n",
    "    # Handle both pipeline and non-pipeline models\n",
    "    if isinstance(model, Pipeline):\n",
    "        model_name = model.steps[-1][0]  # Get name of the last step of the pipeline\n",
    "    else:\n",
    "        model_name = model.__class__.__name__  # Get class name of the model\n",
    "\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (area = {roc_auc:.2f})')\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y, y_preds)\n",
    "    print(f'{model_name} - Confusion Matrix:\\n{cm}')\n",
    "\n",
    "    # Precision and Recall\n",
    "    precision = precision_score(y, y_preds)\n",
    "    recall = recall_score(y, y_preds)\n",
    "    print(f'{model_name} - Precision: {precision}, Recall: {recall}')\n",
    "\n",
    "# Logistic Regression\n",
    "evaluate_model(log_reg, X_train_sm, y_train_sm, kf)\n",
    "\n",
    "# Random Forest\n",
    "evaluate_model(rf, X_train_sm, y_train_sm, kf)\n",
    "\n",
    "# Gradient Boosting\n",
    "evaluate_model(gb, X_train_sm, y_train_sm, kf)\n",
    "\n",
    "# Plotting\n",
    "plt.legend()\n",
    "plt.title('ROC Curves')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "# 6. Model Evaluation\n",
    "# Random Forest model has the best cross-validation scores\n",
    "rf.fit(X_train_sm, y_train_sm)\n",
    "# Predicting using the Random Forest model\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "print('ROC AUC score:', roc_auc_rf)\n",
    "\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_rf)\n",
    "plt.plot(fpr_rf, tpr_rf, label='ROC curve (area = %0.2f)' % roc_auc_rf)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 7. Retention Strategy Suggestions\n",
    "# Generate probabilities using the Random Forest model\n",
    "proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Categorize probabilities into different risk zones\n",
    "proba_bins_rf = pd.cut(proba_rf, bins=[0, 0.2, 0.6, 0.9, 1], labels=['Safe', 'Low Risk', 'Medium Risk', 'High Risk'])\n",
    "print(proba_bins_rf.value_counts())\n",
    "\n",
    "# Employees in the 'High Risk' category might need immediate attention or intervention\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Employees in the 'High Risk' category might need immediate attention or intervention.\n",
    "## Employees in the 'Safe Category' might deserve bonuses.\n",
    "## Employees in the 'Low Risk' and 'Medium Risk' categories might need incentives to increase performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
